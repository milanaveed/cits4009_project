---
title: "CITS4009 - Project 1"
author: "Mila Zhang (22756463)"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
  html_notebook: 
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

# Introduction to the YouTube dataset

This project analises the data set of [Global YouTube Statistics 2023](https://www.kaggle.com/datasets/nelgiriyewithana/global-youtube-statistics-2023) and it can be obtained from the Kaggle platform.

This data collection provides an opportunity to analyse and uncover valuable insights from leading YouTubers. Packed with comprehensive details on high-profile creators, this dataset serves as a treasure for those breaking into content creation, enthusiastic about data, and anyone interested in the constantly changing landscape of online content.

# Performing ETL and setting up for plotting
## Loading libraries
```{r message=FALSE, warning=FALSE}
library(ggplot2)
library(gridExtra)
library(dplyr)
library(ggthemes)
library(numform)
library(treemapify)
library(timeDate)
library(lubridate)
library(reshape2)
library(ca)
library(ggmap)
library(sp)
library(maptools)
library(maps)
```

## Setting up a plotting theme
```{r}
my_color <- "#2061F2"
color_theme <- theme_few() + # Theme based on S. Few's "Practical Rules for Using Color in Charts"
                  theme(plot.title = element_text(color = my_color)) +
                  theme(strip.text.x = element_text(size = 14, colour = "#202020")) 
                  #theme(plot.margin=margin(10,30,10,30))
```

## Extracting data
```{r}
data.path <- './data/youtube_UTF_8.csv'
df <- read.csv(data.path)
```

## Data Overview
### Using head() to analyze the data
```{r message=FALSE, warning=FALSE}
head(df)
```
From the first 6 rows of the data, we can discover some missing values or invalid values which we will convert later according to the need of plotting.

### Using summary() to analyze the data
```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
summary(df)
```

********

## Transforming data
Below are data treatments for missing/invalid/sentinel/outlier values, discretization, normalisation, log-scales and etc.

### Cleaning data

#### Cleaning column created_year
YouTube was created in 2005, so any channel on YouTube should be created in or after 2005. If the created year of a channel is earlier than 2005, then this variable contains invalid value. Also, valid values in the column `created_year` are supposed to be numbers, any NaN value should be turned into NA.
```{r}
df <- mutate(df,
             created_year = ifelse(created_year < 2005, NA, created_year))
```

We can check our data cleaning by counting the occurrences of each value in the column.
```{r}
df %>% count(created_year)
```
Now we have converted those invalid values into NA.

#### Cleaning column Country
When conducting the earnings analysis and plotting the [Highest Yearly Earnings by Country](#earnings-by-country), some values of `nan` were involved initially. We first turn them into NA values.
```{r}
df <- mutate(df,
             Country = ifelse(Country=="nan", NA, Country))
df %>% count(Country)
```
After inspecting the occurrences of each value in the column Country, we found that there are 122 NA values. 

#### Cleaning column category
When conducting the earnings analysis and plotting the [Highest Yearly Earnings by Category](#earnings-by-category), some values of `nan` were involved initially. We first turn them into NA values.
```{r}
df <- mutate(df,
             category = ifelse(category=="nan", NA, category))
df %>% count(category)
```


### Filtering data
TODO:
- take out the NA values in Country
```{r}
#template:
#count_value_2 <- filter(data_counted, column1 == 2)$n
```

## Loading data
Save the cleaned and transformed data
```{r}
#write.csv(df_filtered, "./data/youtube_data_cleaned")
```

# EDA: Content strategy analysis




# EDA: Earnings analysis

## Distribution of earnings
Since "lowest_monthly_earnings" and "highest_monthly_earnings" are right-skewed variables, we will use two histograms to analyze each of the distribution: one with a log10 scale and one with a truncated linear scale.
```{r}
p1 <- ggplot(df, aes(x = lowest_monthly_earnings)) +
  geom_histogram(aes(y=..density..), binwidth= 0.05, fill = "grey") +
  geom_density(color= my_color)+
  scale_x_log10(breaks=c(100,2000,25000,200000))+
  annotate("text", x = 100, y = 0.6, label = paste("The lowest monthly earning peaks"," at around 25000", sep="\n"))+
  ggtitle("Distribution of Lowest Monthly Earnings (Log-scale)") +
  color_theme

lme_Q1 <- boxplot.stats(df$lowest_monthly_earnings)$stats[2]
lme_Q3 <- boxplot.stats(df$lowest_monthly_earnings)$stats[4]
lme_IQR <- lme_Q3-lme_Q1
lme_Q4 <- lme_Q3 + 1.5*lme_IQR

p2 <- ggplot(df, aes(x = lowest_monthly_earnings)) +
  geom_histogram(aes(y=..density..), binwidth=2000, fill = "grey") +
  geom_density(color=my_color)+
  scale_x_continuous(breaks=c(200000,500000))+
  xlim(0,6e+05)+
  ylim(0, 0.00004) +
  annotate("text", x = 200000, y = 2e-05, label = paste("Most of the distribution is concentrated", "at the low end: less than 200000", sep="\n"))+
  ggtitle("Distribution of Lowest Monthly Earnings") +
  color_theme

grid.arrange(p1, p2, ncol=1)
```
Most of the distribution is concentrated at the low end and less than 200000. And the lowest monthly earning peaks at around 25000.

```{r}
p1 <- ggplot(df, aes(x = highest_monthly_earnings)) +
  geom_histogram(aes(y=..density..), binwidth= 0.05, fill = "grey") +
  geom_density(color=my_color)+
  scale_x_log10(breaks=c(100,2000,25000,400000))+
  #annotate("text", x = 100, y = 0.7, label = paste("The lowest monthly earning peaks at around 25000"))+
  ggtitle("Distribution of Highest Monthly Earnings (Log-scale)") +
  color_theme

hme_Q1 <- boxplot.stats(df$highest_monthly_earnings)$stats[2]
hme_Q3 <- boxplot.stats(df$highest_monthly_earnings)$stats[4]
hme_IQR <- hme_Q3-hme_Q1
hme_Q4 <- hme_Q3 + 1.5*hme_IQR

p2 <- ggplot(df, aes(x = highest_monthly_earnings)) +
  geom_histogram(aes(y=..density..), binwidth=5000, fill = "grey") +
  geom_density(color=my_color)+
  xlim(0, hme_Q4) +
  ylim(0, 0.000005) +
  #annotate("text", x = 200000, y = 2e-05, label = paste("Most of the distribution is concentrated", "at the low end: less than 200000", sep="\n"))+
  ggtitle("Distribution of Highest Monthly Earnings") +
  color_theme

grid.arrange(p1, p2, ncol=1)
```

There seem to be some outliers between value 1,000,000 and 1,500,000.

## Earnings by category {#earnings-by-category}
Next we analyze how earnings differ across different YouTube channel categories.
```{r}
# Calculate median for each category
df$median_earnings_category <- with(df, ave(highest_yearly_earnings, category, FUN=median))

# Create the boxplot
ggplot(df, aes(x = reorder(category, median_earnings_category), y = highest_yearly_earnings)) +
  geom_boxplot() +
  coord_flip() +
  ggtitle("Highest Yearly Earnings by Category (Ordered by Median)") +
  color_theme
```
All categories have similar median values except Autos & Vehicles, whose median is significantly larger than others. Pets & Animals channel has the smallest median value of highest yearly earnings.


## Earnings by country {#earnings-by-country}
```{r}
# Compute median values using dplyr
result <- df %>% 
  group_by(Country) %>% 
  summarise(median_earnings = median(highest_yearly_earnings, na.rm = TRUE))
result
```

We can analyse the highest yearly earnings of the top 995 YouTube channels by country.
```{r warning=FALSE}
# Calculate median for each country
df$median_earnings_country <- with(df, ave(highest_yearly_earnings, Country, FUN=median))

# Create the boxplot
ggplot(df, aes(x = reorder(Country, median_earnings_country), y = highest_yearly_earnings)) +
  geom_boxplot() +
  coord_flip() +
  ggtitle("Highest Yearly Earnings by Country (Ordered by Median)") +
  color_theme
```
The popular channel from Latvia has a distinctively higher value of highest yearly earnings among all the countries.

# EDA: Geospatial information
With longitude and latitude provided in the dataset, we are able to visualise the country distribution in the aspect of earnings analysis.
```{r}
# Data preparation
visit.x<-df$Longitude
visit.y<-df$Latitude  

mp<-NULL #Create an empty map
mapworld<-borders("world",colour = "gray50",fill="white") #Draw the map
mp<-ggplot()+mapworld+ylim(-60,90) 
mp2<-mp+geom_point(aes(x=visit.x,y=visit.y,size=df$highest_yearly_earnings),color=my_color)+
  scale_size(range=c(2,9))+
  ggtitle("Geospatial Information About Highest Yearly Earnings")+
  theme(plot.title=element_text(size=25,color="red",face="italic"))+
  theme_grey(base_size = 32)  
mp3<-mp2+color_theme+theme(legend.position = "none")
mp3
```
Countries with high yearly earnings from the channels are mainly located in Europe, South Africa, the middle east and the South-East Asia.

# EDA: Trend by time





# Code for Shiny App
```{r}

```
